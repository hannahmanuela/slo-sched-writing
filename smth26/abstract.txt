Many providers use weights to run a mix of guaranteed applications that have CPU reservations (such as servers) and best effort applications on the same machine. This approach allows providers to run machines at a high utilization by donating unused guaranteed CPU time to best-effort applications. The implementation must ensure, however, that if the load on a guaranteed application goes up, the application can use its full reservation quickly.

This paper finds that Linux’s implementation of weights fails to achieve this goal. We show that guaranteed servers can experience increased latencies in the presence of other workloads. This is because sometimes guaranteed servers are not scheduled, even though they are runnable and their group is under-using its reservation. The core reason for such scheduling anomalies is that Linux’s scheduler has a per-core design: it accounts on a per-core basis, and doesn’t consult other cores’ runqueues when making a scheduling decision.

This paper introduces GlobalHeap, a new scheduler with global design that implements weights correctly, and in a scalable manner. It assigns each runnable process a virtual time, and uses the relaxed multiqueues data structure  to implement a global heap of processes sorted by virtual time. GlobalHeap augments multiqueues to take core-affinity into account when selecting a process to run, so that hot processes can benefit from warm L1/L2 caches.

Experimental results with an implementation of GlobalHeap in Linux on a 56-core machine shows that GlobalHeap avoids the scheduling anomalies that Linux experiences, and consistently provides low tail-latencies for guaranteed servers.
