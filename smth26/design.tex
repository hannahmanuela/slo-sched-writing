\section{\beclass{} Design in Linux}\label{s:design}

We design \beclass{} to implement our approach while fitting into Linux's existing
scheduler design.

Linux already has multiple scheduling classes that are accessible to users,
which are (in descending order of priority): \deadlineclass{}, \fifoclass{}, and
\normalclass{}. Generally speaking most load is expected to fall into the
\normalclass{} scheduling class (hence the name). It is the default scheduling
class, and it is only within the \normalclass{} scheduling class that the
\cgroups{} cpu.weight interface is relevant.

Each scheduling class exists completely separately: classes maintain their own
runqueues and per-entity state; implement their own scheduling algorithms to
choose from the entities on their runqueue; and balance the load across
runqueues on different cores. Linux isolates strictly between different
scheduling classes: it only schedules a lower scheduling class if the higher
scheduling classes found nothing to run, and each scheduling class tries to
steal work from other cores before returning that it has nothing to run. 

We emulate the same behavior in the design of \beclass{}. The goal is to enforce
the maxim that no \beclass{} userspace process is ever running if a
\normalclass{} task is waiting for a core. In order to do so, the scheduler must
enforce the priorities in three different places:
\begin{enumerate}
    \item \local: in picking the next entity to run on each core, it must ensure
        that no \beclass{} entity will be chosen if there is a runnable
        \normalclass{} entity,
    \item \entry: when waking up a \normalclass{} entity on a core already
        running a \normalclass{} entity, it must look for other cores running
        \beclass{} entities the new one can interrupt,
    \item \exit: it must try to steal queued \normalclass{} entities from other
        cores before running a \beclass{} entity, if one was chosen.
\end{enumerate}

These three pieces together create the desired strict and global priority.
\local{} ensures the property locally on each core. The second and third enforce
it globally, by interposing on boundary crossings of the \normalclass{} class.
If a core is currently running a \beclass{} thread $t$, the scheduler knows that
there are no queued and waiting \normalclass{} threads anywhere. If there were
ones before it started running $t$, the \exit{} check would have stolen it, and
if a new \normalclass{} thread wakes up while $t$ is running, the \entry{} check
ensures that the core where it wakes up will interrupt $t$.

% In enforcing this priority in Linux, parking becomes an emergent behavior rather
% than an explicit state that the scheduler has to put BE processes into. Linux
% already manages I/O interrupts, including acknowledging network packets, in
% kernelspace interrupt handlers. These run irrespective of whether and when the
% userspace process is scheduled, and simply write the relevant message buffers to
% the processes' memory. This means that the dividing line between what is
% application logic (user space) and what is necessary for the BE to not crash
% (kernel space) overlaps with what the scheduler is able to enforce vs not: the
% scheduler cannot preempt a kernel space process handling an interrupt unless it
% is explicitly marked as preemptible.
