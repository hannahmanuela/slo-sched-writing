Many providers use \cgroups{} weights to run a mix of \textit{guaranteed} applications
that have CPU reservations (such as servers) and \textit{best effort}
applications on the same machine.
This approach allows providers to run machines at a high
utilization by donating unused guaranteed CPU time to best-effort
applications.  The \cgroups{} implementation must ensure, however, that
if the load on a guaranteed application goes up, the application can use its full
reservation quickly.

This paper finds that Linux's implementation of \cgroups{} weights fails to
achieve this goal.
We show that guaranteed servers can experience increased
latencies in the presence of other workloads.
This is because sometimes guaranteed servers are not scheduled, even
though they are runnable and their group is under-using its reservation. The
core reason for such scheduling anomalies is that Linux's scheduler has a
{\it per-core} design: it accounts \cgroups{} on a per-core basis, and doesn't
consult other cores' runqueues when making a scheduling decision.

This paper introduces \sys{}, a new scheduler with {\it global
design} that implements \cgroups{} weights correctly, and in a
scalable manner. It assigns each runnable process a virtual time, and
uses the approximate \textit{multiqueues} data
structure~\cite{multiqueue:2015} to implement a global heap of
processes sorted by virtual time.  \sys augments multiqueues 
to take core-affinity into account when selecting a process to run,
so that hot processes can benefit from warm L1/L2 caches.

Experimental results with an implementation of \sys in Linux on a
56-core machine shows that \sys avoids the scheduling anomalies that
Linux experiences, and consistently provides low tail-latencies for
guaranteed servers.
